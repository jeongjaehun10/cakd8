{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ox-qCraepbUx"],"mount_file_id":"1i0EzZk9u-sDp5jGmDbw2CBonWDNXZz58","authorship_tag":"ABX9TyOktmGHi4KgqUE4klkSC9p6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["https://drive.google.com/drive/folders/1xq0Y7SJ6kFHjEfC9swqcNpXdUP4aVVaY?usp=sharing\n"," 구글 드라이브"],"metadata":{"id":"qxvln-O-Fe7d"}},{"cell_type":"code","source":["486 604 8800\n","1215"],"metadata":{"id":"HX2Z9z8CqnrU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 딥러닝 복습"],"metadata":{"id":"0_vpU8JelskS"}},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) =mnist.load_data() \n","\n","x_train, x_test = x_train/255.0, x_test/255.0 # 유의점은 실수로 만들어주어야함 0~1사이로 만듬\n","\n","x_train = x_train.reshape((60000, 28*28))\n","x_test = x_test.reshape((10000, 28*28))\n","\n","model =Sequential([\n","    layers.Dense(512, activation='relu'), # 512는 아웃풋이다. \n","    layers.Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics='acc')\n","model.fit(x_train, y_train, epochs=5, batch_size=128)\n"],"metadata":{"id":"2iwQxeunYQ1E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28*28))\n","train_images= train_images.astype('float32')/255\n","\n","test_images = test_images.reshape((10000, 28*28))\n","test_images= test_images.astype('float32')/255\n","\n","\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n","network.add(layers.Dense(10, activation='softmax'))\n","network.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics='acc')\n","\n","\n","network.fit(train_images, train_labels, epochs=5, batch_size=128) # 에포크 5번 반복하겠다.\n"],"metadata":{"id":"-Vzkif7AYQof"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# cnn"],"metadata":{"id":"akyihYYLYPDP"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8U5rBsmPUUr3","executionInfo":{"status":"ok","timestamp":1670564816378,"user_tz":-540,"elapsed":23218,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"557a5b05-c17f-4523-f3c0-ddd8a597497d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["path ='/content/drive/My Drive/train'\n"],"metadata":{"id":"3j1CdFACa_Fx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ctrl shift z 되돌리기 "],"metadata":{"id":"m0u8t9IEnGcP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OeTzkCiUTOtR","executionInfo":{"status":"ok","timestamp":1670564006936,"user_tz":-540,"elapsed":7260,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"f2f659c9-4be8-4e77-a99d-51be0c3eb353"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n","                                                                 \n","=================================================================\n","Total params: 92,672\n","Trainable params: 92,672\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras import layers\n","from tensorflow.keras import models\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3,3), activation ='relu', input_shape=(28,28, 1))) # 3x3 필터 32개\n","model.add(layers.MaxPool2D((2,2))) # 풀링은 가로 세로 공간을 줄이는 연산\n","model.add(layers.Conv2D(64, (3,3), activation ='relu')) # 3x3 필터 32개\n","model.add(layers.MaxPool2D((2,2))) # 풀링은 가로 세로 공간을 줄이는 연산\n","model.add(layers.Conv2D(128, (3,3), activation ='relu')) # 3x3 필터 32개\n","model.summary() # 2씩줄고 반줄고, 2씩줄고 반줄고 한다. \n","# 파라미터가 의미하는 것은 가중치이다. \n","# conv층 다음 완전 연결 층 갈려면 flatten과정을 거침 "]},{"cell_type":"code","source":["model.add(layers.Flatten()) # 완전 연결 층에서는 학습시 공간정보를 \n","model.add(layers.Dense(64, activation= 'relu'))\n","model.add(layers.Dense(10, activation='softmax'))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f69W1j78T8gw","executionInfo":{"status":"ok","timestamp":1670564014188,"user_tz":-540,"elapsed":519,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"2c99c9c9-b7e3-42e7-9a97-ffb505d8a700"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n","                                                                 \n"," flatten (Flatten)           (None, 1152)              0         \n","                                                                 \n"," dense (Dense)               (None, 64)                73792     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 167,114\n","Trainable params: 167,114\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) =mnist.load_data()\n","train_images = train_images.reshape((60000, 28,28,1))\n","train_images = train_images.astype('float32')/255\n","\n","test_images =test_images.reshape((10000,28,28,1))\n","test_images =test_images.astype('float32')/255\n","\n","train_labels =to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_wD_iuaV44i","executionInfo":{"status":"ok","timestamp":1670564020002,"user_tz":-540,"elapsed":2571,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"50fd40ff-f4f2-43ae-e9f3-5fa5d2224206"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"code","source":["model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics='acc')\n","model.fit(train_images, train_labels, epochs=5, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wph1-rjNXIZw","executionInfo":{"status":"ok","timestamp":1670564052791,"user_tz":-540,"elapsed":29762,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"b380e0a2-9232-490a-da02-39260ae9eb99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","938/938 [==============================] - 12s 5ms/step - loss: 0.1528 - acc: 0.9517\n","Epoch 2/5\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0415 - acc: 0.9873\n","Epoch 3/5\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0295 - acc: 0.9908\n","Epoch 4/5\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0219 - acc: 0.9935\n","Epoch 5/5\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0162 - acc: 0.9949\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3b823cf0d0>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","test_acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1GO3Y7cXh98","executionInfo":{"status":"ok","timestamp":1670564058421,"user_tz":-540,"elapsed":1466,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"7e7f43b2-f97f-4ea9-955c-573a41f1c123"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 4ms/step - loss: 0.0286 - acc: 0.9928\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9927999973297119"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# 우리가 목표하는 것은 일반화이다. "],"metadata":{"id":"Ta51s1w_YImK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 강아지 고양이 복습하기"],"metadata":{"id":"QX9oDs3WZOoI"}},{"cell_type":"code","source":["import shutil\n","shutil.rmtree(\"./cats_vs_dogs\") # 파일 지우기"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"rZ-7ifF8eG2v","executionInfo":{"status":"error","timestamp":1670568523737,"user_tz":-540,"elapsed":6,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"08bac513-5cee-43de-87bb-1e89acb2cd49"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-bc3e77dfc410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./cats_vs_dogs\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 파일 지우기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cats_vs_dogs'"]}]},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.layers import Input, Rescaling, Conv2D, MaxPooling2D, Dense, Flatten"],"metadata":{"id":"fJ2TO20xZSuy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gdown\n","\n","url = \"https://drive.google.com/uc?id=1ipzN9okFFT3oieklsrfr6iUHzjPAbT9i\"\n","gdown.download(url, \"cats_and_dogs.tar\") "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"yvvx_5g0bepL","executionInfo":{"status":"ok","timestamp":1670568547046,"user_tz":-540,"elapsed":7132,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"1d5c2cb2-b3a2-4c27-fc29-43ca2389f26a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1ipzN9okFFT3oieklsrfr6iUHzjPAbT9i\n","To: /content/cats_and_dogs.tar\n","100%|██████████| 94.0M/94.0M [00:00<00:00, 375MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'cats_and_dogs.tar'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["!tar -xvf cats_and_dogs.tar"],"metadata":{"id":"9SWbY9pQbgnD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.utils import image_dataset_from_directory\n","# 텐서로 디코딩.. 데이터 셋을 배치사이즈 단위로 가져올 수 잇게해주는 메서드  \n","# 배치사이즈 32로 한다.\n","\n","dir = pathlib.Path(\"./cats_and_dogs\")\n","\n","train_dataset = image_dataset_from_directory(\n","    dir / 'train',\n","    image_size = (180, 180),\n","    batch_size = 32\n",")\n","\n","validation_dataset = image_dataset_from_directory(\n","    dir / 'validation',\n","    image_size = (180, 180),\n","    batch_size = 32\n",")\n","\n","test_dataset = image_dataset_from_directory(\n","    dir / 'test',\n","    image_size = (180, 180),\n","    batch_size = 32\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vVWcZroJdCc2","executionInfo":{"status":"ok","timestamp":1670566279996,"user_tz":-540,"elapsed":7,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"2072970d-aca9-47f5-c3a0-a0d38b16a0a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2000 files belonging to 2 classes.\n","Found 1000 files belonging to 2 classes.\n","Found 1000 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["inputs =Input(shape=(180, 180, 3))\n","x = layers.Rescaling(1./255)(inputs)\n","x = layers.Conv2D(filters =32, kernel_size=3, activation=\"relu\")(x)\n","x=  layers.MaxPooling2D(pool_size=2)(x)\n","\n","x = layers.Conv2D(filters =64, kernel_size=3, activation=\"relu\")(x)\n","x=  layers.MaxPooling2D(pool_size=2)(x)\n","\n","x = layers.Conv2D(filters =128, kernel_size=3, activation=\"relu\")(x)\n","x=  layers.MaxPooling2D(pool_size=2)(x)\n","\n","x = layers.Conv2D(filters =256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","\n","model=keras.Model(inputs= inputs, outputs=outputs)"],"metadata":{"id":"poHz2goeZr19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics =[\"accuracy\"])"],"metadata":{"id":"gOQ0MgaNc9w0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callbacks =[\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"convnet_from_scrath.keras\", save_best_only=True, monitor=\"val_loss\")]"],"metadata":{"id":"PWrHwSLXg94A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit( train_dataset, epochs=10, validation_data=validation_dataset, callbacks = callbacks)\n","# labels가 없는 이유는 이미되있음 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EqeJHlbAhdmf","executionInfo":{"status":"ok","timestamp":1670567386081,"user_tz":-540,"elapsed":55710,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"79abb154-0448-460e-fc7c-78919b026ead"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","63/63 [==============================] - 6s 76ms/step - loss: 0.8354 - accuracy: 0.5145 - val_loss: 0.6780 - val_accuracy: 0.5630\n","Epoch 2/10\n","63/63 [==============================] - 5s 78ms/step - loss: 0.7132 - accuracy: 0.5760 - val_loss: 0.6641 - val_accuracy: 0.6040\n","Epoch 3/10\n","63/63 [==============================] - 5s 73ms/step - loss: 0.6611 - accuracy: 0.6090 - val_loss: 0.6812 - val_accuracy: 0.5850\n","Epoch 4/10\n","63/63 [==============================] - 5s 74ms/step - loss: 0.6252 - accuracy: 0.6670 - val_loss: 0.5944 - val_accuracy: 0.6730\n","Epoch 5/10\n","63/63 [==============================] - 5s 72ms/step - loss: 0.5631 - accuracy: 0.7120 - val_loss: 0.9609 - val_accuracy: 0.5610\n","Epoch 6/10\n","63/63 [==============================] - 5s 73ms/step - loss: 0.5406 - accuracy: 0.7205 - val_loss: 0.6750 - val_accuracy: 0.6740\n","Epoch 7/10\n","63/63 [==============================] - 5s 73ms/step - loss: 0.5071 - accuracy: 0.7655 - val_loss: 0.6594 - val_accuracy: 0.6680\n","Epoch 8/10\n","63/63 [==============================] - 5s 71ms/step - loss: 0.4391 - accuracy: 0.8055 - val_loss: 0.6831 - val_accuracy: 0.7090\n","Epoch 9/10\n","63/63 [==============================] - 5s 72ms/step - loss: 0.3922 - accuracy: 0.8275 - val_loss: 0.7769 - val_accuracy: 0.7110\n","Epoch 10/10\n","63/63 [==============================] - 5s 73ms/step - loss: 0.3504 - accuracy: 0.8490 - val_loss: 0.7918 - val_accuracy: 0.7100\n"]}]},{"cell_type":"code","source":["### 테스트 세트에서 모델 평가하기\n","test_model = keras.models.load_model(\"convnet_from_scrath.keras\")\n","# 전문가가 만든 것을 가지고 와서 정확도를 더 높임 \n","test_loss, test_acc = test_model.evaluate(test_dataset)\n","print(f'테스트 정확도 : {test_acc:.3f}') "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpJ1nNC1hfyL","executionInfo":{"status":"ok","timestamp":1670567295789,"user_tz":-540,"elapsed":3373,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"373557d8-4c78-4106-f49f-09cd83b93245"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 2s 36ms/step - loss: 0.5966 - accuracy: 0.7010\n","테스트 정확도 : 0.701\n"]}]},{"cell_type":"code","source":["list(train_dataset) # 파일보기 "],"metadata":{"id":"H56CC-YIj3Xa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in train_dataset:\n","  print(i)"],"metadata":{"id":"-u8Yyz1diB8y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데이터 증식\n","data_augmentation =keras.Sequential([\n","    layers.RandomFlip(\"horizontal\"),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.2),\n","])\n","\n","inputs =Input(shape=(180, 180, 3))\n","x= data_augmentation(inputs)\n","x = layers.Rescaling(1./255)(x)\n","x = layers.Conv2D(filters =32, kernel_size=3, activation=\"relu\")(x)\n","x=  layers.MaxPooling2D(pool_size=2)(x)\n","\n","x = layers.Conv2D(filters =64, kernel_size=3, activation=\"relu\")(x)\n","x=  layers.MaxPooling2D(pool_size=2)(x)\n","\n","x = layers.Conv2D(filters =128, kernel_size=3, activation=\"relu\")(x)\n","x=  layers.MaxPooling2D(pool_size=2)(x)\n","\n","x = layers.Conv2D(filters =256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","x = layers.Dropout(0.5)(x)\n","\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","\n","model=keras.Model(inputs= inputs, outputs=outputs)\n","\n","model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics =[\"accuracy\"])\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","      filepath=\"convnet_from_scrath_with_augmentation.keras\",\n","      save_best_only=True,\n","      monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_dataset,\n","    epochs=5,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBUMsiucjkCw","executionInfo":{"status":"ok","timestamp":1670567568129,"user_tz":-540,"elapsed":41891,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"87a35d0f-a7d8-4eb3-9a04-8ee508798ace"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","63/63 [==============================] - 8s 99ms/step - loss: 0.7321 - accuracy: 0.5330 - val_loss: 0.6872 - val_accuracy: 0.5070\n","Epoch 2/5\n","63/63 [==============================] - 6s 97ms/step - loss: 0.7071 - accuracy: 0.5830 - val_loss: 0.6728 - val_accuracy: 0.5780\n","Epoch 3/5\n","63/63 [==============================] - 6s 98ms/step - loss: 0.6736 - accuracy: 0.6100 - val_loss: 0.6297 - val_accuracy: 0.6150\n","Epoch 4/5\n","63/63 [==============================] - 7s 105ms/step - loss: 0.6562 - accuracy: 0.6470 - val_loss: 0.5936 - val_accuracy: 0.6730\n","Epoch 5/5\n","63/63 [==============================] - 7s 99ms/step - loss: 0.6362 - accuracy: 0.6540 - val_loss: 0.6197 - val_accuracy: 0.6460\n"]}]},{"cell_type":"code","source":["ls # 현재 폴더내 파일"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nvx_aktClXhX","executionInfo":{"status":"ok","timestamp":1670568047160,"user_tz":-540,"elapsed":493,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"f69b44ba-3b88-45b5-cdae-ea4359df1bfc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mcats_and_dogs\u001b[0m/     convnet_from_scrath.keras                    \u001b[01;34mdrive\u001b[0m/\n","cats_and_dogs.tar  convnet_from_scrath_with_augmentation.keras  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["import os # 길 지정해줘서 하기..\n","\n","train_dir = './cats_and_dogs/train'\n","validation_dir = './cats_and_dogs/validation'\n","test_dir = './cats_and_dogs/test'\n","\n","# 훈련용 고양이 사진 디렉터리\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","\n","# 훈련용 강아지 사진 디렉터리\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","\n","# 검증용 고양이 사진 디렉터리\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","\n","# 검증용 강아지 사진 디렉터리\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n","\n","# 테스트용 고양이 사진 디렉터리\n","test_cats_dir = os.path.join(test_dir, 'cats')\n","\n","# 테스트용 강아지 사진 디렉터리\n","test_dogs_dir = os.path.join(test_dir, 'dogs') \n","\n","\n","\n","import keras\n","import scipy\n","\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","# 모든 이미지를 1/255 부동소수점으로 스케일을 조정하는 제너레이터 객체를 만들자.\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(       \n","        train_dir,                # 타깃 디렉터리\n","        target_size=(150, 150),  # 모든 이미지를 150 × 150 크기로 바꿉니다\n","        batch_size=20,           #  20개씩 배치로 생산        \n","        class_mode='binary')     # 이진 레이블. 만약 다중클래스라면 'categorical'\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')\n","\n","test_generator = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')"],"metadata":{"id":"C715cIsfoQJC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 경사하강법 폭 건너뛰는 것 방지 모멘텀 탄력받는 것 너무 건너뛰지말라고 방지\n","# 그중하나가 rmsprop이다. \n","# ImageDataGenerator는 데이터 증식이나 scaling 할때 쓴다.\n","# 필터링의 실체는 연산과정"],"metadata":{"id":"bh5DMmqimFkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Nqh2hRxDoxXB","executionInfo":{"status":"ok","timestamp":1670569717571,"user_tz":-540,"elapsed":6,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"5edc9e99-f976-4cbe-82c8-373ba54bc3d8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["CNN\n","\n","완전 연결 네트워크의 문제점으로부터 시작\n","\n","- 매개변수의 폭발적인 증가\n","- 공간 추론의 부족\n"," - 픽셀 사이의 근접성 개념이 완전 연결 계층에서는 손실됨\n","- 합성곱 계층은 입력 이미지가 커져도 튜닝해야 할 매개변수 개수에 영향을 주지 않음\n","- 또한 그 어떠한 이미지에도 그 차원 수와 상관없이 적용될 수 있음\n","\n","CNN\n","\n","완전 연결 네트워크의 문제점으로부터 시작\n","\n","- 매개변수의 폭발적인 증가\n","- 공간 추론의 부족\n"," - 픽셀 사이의 근접성 개념이 완전 연결 계층에서는 손실됨\n","- 합성곱 계층은 입력 이미지가 커져도 튜닝해야 할 매개변수 개수에 영향을 주지 않음\n","- 또한 그 어떠한 이미지에도 그 차원 수와 상관없이 적용될 수 있음\n","\n","https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4\n","\n","\n","컨볼루션 연산\n","- 필터 연산\n"," - 입력 데이터에 필터를 통한 어떠한 연산을 진행\n"," - 필터에 대응하는 원소끼리 곱하고 그 합을 구함\n"," - 연산이 완료된 결과 데이터를 특징 맵이라 부름\n","- 필터\n"," - 커널이라고도 하며 흔히 사진 어플에서 사용하는 '이미지 필터'와 비슷한 개념\n"," - 필터의 사이즈는 '거의 항상 홀수'\n","  - 짝수이면 패딩이 비대칭이 되어버림\n","  - 왼쪽, 오른쪽을 다르게 주어야함\n","  - 중심위치가 존재, 즉 구별된 하나의 픽셀(중심 픽셀)이 존재\n"," - 필터의 학습 파라미터 개수는 입력 데이터의 크기와 상관없이 일정, 따라서 과적합을 방지할 수 있음\n","\n","An example of convolution operation  \n","https://www.researchgate.net/figure/An-example-of-convolution-operation-in-2D-2_fig3_324165524\n","\n","- 일반적으로 합성곱 연산을 한 후의 데이터 사이즈는 (n - f + 1) x (n - f + 1)\n","\n","- 패딩과 스트라이드\n"," - 필터(커널) 사이즈와 함께 입력 이미지와 출력 이미지의 사이즈를 결정하기 위해 사용\n"," - 사용자가 결정할 수 있음\n"," - 패딩은 입력 데이터의 주변을 특정 값으로 채우는 기법. 주로 0으로 많이 채움\n"," - 출력 데이터의 크기 : (n + 2p - f +1) x (n + 2p -f + 1)\n"," - valid(패딩을 주지 않음) 와 same(패딩을 주어 입력 이미지와 연산 후의 이미지가 같게 함), 패딩의 크기는 (k-1)/2 (단, stride=1)\n"," - 스트라이드는 필터를 적용하는 간격을 의미\n","\n"," https://kingnamji.tistory.com/24\n","\n"," https://m.blog.naver.com/jevida/221841296542\n","\n","풀링(Pooling)\n","- 필터 사이즈 내에서 특정 값을 추출하는 과정\n","- Max Pooling : 출력 데이터의 사이즈 계산은 컨볼루션 연산과 동일\n","- 특징맵의 크기를 절반으로 줄임\n","- 모델이 물체의 주요한 특성을 학습하도록 해주며 컨볼루션 신경망이 이동 불변성 특성을 가지게 해줌\n","- 모델의 파라미터 개수를 줄여주고 연산 속도를 빠르게 해줌\n","\n","https://cs231n.github.io/convolutional-networks/\n","\n","\n","LeNet-5 \n","- LeNet-5는 복잡하지 않은 망을 이용하여 (당시 기준)높은 성능을 보여주었을 뿐만 아니\n","라 Convolutional layer와 pooling의 조합을 반복하는 현대적인 CNN 구조를 제안했다는 점에서 의미가 있는 모델 \n","- 남이 만들어 놓은 거 쓴다. \n","- https://velog.io/@woojinn8/CNN-Network-1.-LeNet\n","\n","\n","Visual Geometry Group Net(VGGNet)\n","- 활성화 함수로 ReLU 사용, Dropout 적용\n","- 합성곱과 풀링 계층으로 구성된 블록과 분류를 위한 완전 연결계층으로 결합된 전형적인 구조\n","- 인위적으로 데이터셋을 늘림\n"," - 이미지 변환, 좌우 반전 등의 변환을 시도\n","- 몇 개의 합성곱 계층과 최대 풀링 계층이 따르는 5개의 블록과 3개의 완전 연결계층으로 구성\n","설명은 불가하다.\n","- 모든 합성곱과 최대 풀링 계층에 padding='SAME' 적용<br>\n","https://buomsoo-kim.github.io/keras/2018/05/02/Easy-deep-learning-with-Keras-8.md/ <br>\n","- 패딩 same은 크기 안준다.\n","- 합성곱 계층에는 stride=1, 활성화 함수로 ReLU 사용\n","- 특성맵 깊이를 증가 시킴\n","- 척도 변경을 통한 데이터 보강(Data Augmentation)\n","- 3x3 커널을 갖는 두 합성곱 계층을 쌓은 스택이 5x5 커널을 갖는 하나의 합성곱 계층과 동일한 수용영역(ERF)을 가짐\n","- 11X11 사이즈의 필터 크기를 가지는 AlexNet과 비교하여 더 작은 합성곱 계층을 더 많이 포함해 더 큰 ERF를 얻음\n","- ERF는 저장역역 \n","- 이와 같이 합성곱 계층의 개수가 많아지면 매개변수 개수를 줄이고 비선형성을 증가시킴\n","- VGG-19 아키텍쳐는 VGG-16에 3개의 합성곱 계층을 추가\n","\n","- LeNet-5, AlexNet, VGG-16, ResNet, Inception Network  \n","https://wooono.tistory.com/233\n","\n","drop out 과적합\n","- 은행에서 직원 내부의 부정 직원이 오랫동안 같이 있으면\n","짜고 칠수 있다.\n","\n","\n","- VGG-19 아키텍쳐\n","\n","  - VGG-16에 3개의 합성곱 계층을 추가\n","\n","  <br>   \n","\n","  <img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16.png\">\n","  <center>VGG-16 아키텍쳐</center>\n","\n","  <sub>[이미지 출처] https://neurohive.io/en/popular-networks/vgg16/ </sub>\n","\n","\n","<br>\n","\n","- (참고) ILSVRC의 주요 분류 metric 중 하나는 `top-5`\n","  \n","  - 상위 5개 예측 안에 정확한 클래스가 포함되면 제대로 예측한 것으로 간주\n","\n","  - 일반적인 `top-k` metric의 특정 케이스\n","\n","GoogLeNet, Inception 모듈\n","- VGGNet을 제치고 같은 해 분류 과제에서 1등을 차지\n","- 인셉션 블록이라는 개념을 도입하여 인셉션 네트워크라고도 불림\n","- Inception Module은 layer에 1x1 Convolution layer를 추가해 bottleneck layer를 구현함으로써,\n","-channel 수를 감소시키며, 연산량을 줄이는 구조입니다.\n","-이것이 inception module의 기본 아이디어이며, Inception Network는 이러한 Inception Module의 집합입니다.\n","\n","# GoogLeNet, Inception 모듈\n","\n","- VGGNet을 제치고 같은 해 분류 과제에서 1등을 차지\n","\n","- 인셉션 블록이라는 개념을 도입하여, **인셉션 네트워크(Inception Network)**라고도 불림\n","- 남이 만들어 놓은 거 쓴다.\n","\n","  <img src=\"https://miro.medium.com/max/2800/0*rbWRzjKvoGt9W3Mf.png\">\n","\n","  <sub>[이미지 출처] https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5</sub>\n","\n","- 특징 \n","  \n","  - CNN 계산 용량을 최적화하는 것을 고려\n","\n","  - 전형적인 합성곱, 풀링 계층으로 시작하고, 이 정보는 9개의 인셉션 모듈 스택을 통과  \n","    해당 모듈을 하위 네트워크라고도 함\n","\n","  - 각 모듈에서 입력 특징 맵은 서로 다른 계층으로 구성된 4개의 병렬 하위 블록에 전달되고, 이를 서로 다시 연결\n","  1개로\n","\n","  - 모든 합성곱과 풀링 계층의 padding옵션은 \"SAME\"이며 `stride=1`,  \n","    활성화 함수는 `ReLU` 사용\n","\n","- 기여\n","\n","  - 규모가 큰 블록과 병목을 보편화\n","\n","  - 병목 계층으로 1x1 합성곱 계층 사용\n","\n","  - 완전 연결 계층 대신 풀링 계층 사용\n","\n","  - 중간 소실로 경사 소실 문제 해결\n","\n","  <img src=\"https://norman3.github.io/papers/images/google_inception/f01.png\">\n","\n","  <sub>[이미지 출처] https://norman3.github.io/papers/docs/google_inception.html</sub>\n"],"metadata":{"id":"ox-qCraepbUx"}},{"cell_type":"markdown","source":["# vgg16"],"metadata":{"id":"2Y5qLTTM0Lyd"}},{"cell_type":"code","source":["# 남이 잘해놓은거 같이 쓴다. \n","from tensorflow.keras.applications import VGG16\n","vgg_net = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n","                pooling=None, classes=1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-Lku4b6xk5q","executionInfo":{"status":"ok","timestamp":1670571237596,"user_tz":-540,"elapsed":29968,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"23091c30-7c41-44b8-cf26-dd49032f4be1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467096/553467096 [==============================] - 25s 0us/step\n"]}]},{"cell_type":"code","source":["vgg_net.summary()\n","# conv2 2개 pooling, conv2 2개 pooling, conv2 3개 pooling,"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHituu0IzYKE","executionInfo":{"status":"ok","timestamp":1670571240021,"user_tz":-540,"elapsed":632,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"d041cb9b-0cca-4a64-8338-a4801f985434"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n"," predictions (Dense)         (None, 1000)              4097000   \n","                                                                 \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# vgg19"],"metadata":{"id":"d1wl0rwzzftQ"}},{"cell_type":"code","source":["from tensorflow.keras.applications import VGG19\n","vgg_net = VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n","                pooling=None, classes=1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3R_ovyt0P56","executionInfo":{"status":"ok","timestamp":1670571475086,"user_tz":-540,"elapsed":29450,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"53d3dfb3-5d2f-400d-eb9d-ebfad9d61bd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n","574710816/574710816 [==============================] - 27s 0us/step\n"]}]},{"cell_type":"code","source":["vgg_net.summary() #  각층마다 Conv2D가 추가됨 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TE2FxCzd0Uqb","executionInfo":{"status":"ok","timestamp":1670571475086,"user_tz":-540,"elapsed":29,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"b1c23943-4732-4fa3-a106-34072792fffd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg19\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n"," predictions (Dense)         (None, 1000)              4097000   \n","                                                                 \n","=================================================================\n","Total params: 143,667,240\n","Trainable params: 143,667,240\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["image_net이란?"],"metadata":{"id":"vhBnR85D0Y-y"}},{"cell_type":"code","source":["google.inception"],"metadata":{"id":"Or8rAtuM1d_a"},"execution_count":null,"outputs":[]}]}