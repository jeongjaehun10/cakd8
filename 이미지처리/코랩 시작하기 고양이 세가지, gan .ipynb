{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1eKb7LL1487EkOhlt7zRyFsETxCfvmRLR","authorship_tag":"ABX9TyMF9R+McNx6DcNzCynKZ6ZY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jiXsRtYbQ--8"},"outputs":[],"source":["import gdown # 구글 드라이브는 파일이 크면 시간이 오래걸림 ,그래서 이걸 사용 큰 파일 받는 데 용이\n","# "]},{"cell_type":"code","source":["url = \"https://drive.google.com/uc?id=1ipzN9okFFT3oieklsrfr6iUHzjPAbT9i\" # 다른 사람 폴더 파일 가져옴\n","gdown.download(url, \"cats_and_dogs.tar\")  # 압축된 상태"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"t4TNNMVsRKua","executionInfo":{"status":"ok","timestamp":1670212366875,"user_tz":-540,"elapsed":17609,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"5720b52b-93e0-4b96-e00a-bb8493e2cc0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1ipzN9okFFT3oieklsrfr6iUHzjPAbT9i\n","To: /content/cats_and_dogs/cats_and_dogs.tar\n","100%|██████████| 94.0M/94.0M [00:00<00:00, 246MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'cats_and_dogs.tar'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["ls # 현재 위치"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jav_mx4hRyI8","executionInfo":{"status":"ok","timestamp":1670211862893,"user_tz":-540,"elapsed":252,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"fcc6efa9-e0f5-4e8a-87c4-dc45dd170de5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cats_and_dogs.tar  \u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["ll # ls 보기 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gScAVFzAR3mk","executionInfo":{"status":"ok","timestamp":1670211755712,"user_tz":-540,"elapsed":248,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"4efd507a-74a7-4597-eb5b-1200d3b739e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 91792\n","-rw-r--r-- 1 root 93983232 Dec  5 03:39 cats_and_dogs.tar\n","drwx------ 5 root     4096 Dec  5 03:39 \u001b[0m\u001b[01;34mdrive\u001b[0m/\n","drwxr-xr-x 1 root     4096 Dec  1 20:08 \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["ls-al # d는 디렉토리  r리드 w 일기 x 실행권한 다있으면 rwx/ root는 소유자  파일리스트 확인 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RqaOuA1QR5WQ","executionInfo":{"status":"ok","timestamp":1670211757443,"user_tz":-540,"elapsed":367,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"3ec789b2-130c-44e9-f501-1a58501394eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 91804\n","drwxr-xr-x 1 root root     4096 Dec  5 03:39 \u001b[0m\u001b[01;34m.\u001b[0m/\n","drwxr-xr-x 1 root root     4096 Dec  5 03:30 \u001b[01;34m..\u001b[0m/\n","-rw-r--r-- 1 root root 93983232 Dec  5 03:39 cats_and_dogs.tar\n","drwxr-xr-x 4 root root     4096 Dec  1 20:07 \u001b[01;34m.config\u001b[0m/\n","drwx------ 5 root root     4096 Dec  5 03:39 \u001b[01;34mdrive\u001b[0m/\n","drwxr-xr-x 1 root root     4096 Dec  1 20:08 \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["!tar -xvf cats_and_dogs.tar # 컨트롤 스페이스 자동완성 압축풀기  시스템 명령\n","# 유닉스 명령어 ! 를 넣어야 함 "],"metadata":{"id":"psi5t9mjR_Dk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OoIzRI0uSaow","executionInfo":{"status":"ok","timestamp":1670211883157,"user_tz":-540,"elapsed":4,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"087a5376-47c7-46c9-d9d1-5a1e38b95866"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mcats_and_dogs\u001b[0m/  cats_and_dogs.tar  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["# 접근\n","cd cats_and_dogs "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVtyDrK1TJtN","executionInfo":{"status":"ok","timestamp":1670212421670,"user_tz":-540,"elapsed":233,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"0c4e7893-af73-400a-81b8-c8e9389640b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/cats_and_dogs/cats_and_dogs\n"]}]},{"cell_type":"code","source":["ls test/cats #test파일내 사진 보기 "],"metadata":{"id":"_6e-caF8TLK4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 주석 나오기 \n","cd .. "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pI2ZPmYzTOHw","executionInfo":{"status":"ok","timestamp":1670212509918,"user_tz":-540,"elapsed":235,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"b2c2451d-89b2-4cc8-ef1f-f2274299967d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFuP9XvibDFS","executionInfo":{"status":"ok","timestamp":1670212528980,"user_tz":-540,"elapsed":10,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"710b796b-643c-465e-8aff-788489c82bf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mcats_and_dogs\u001b[0m/  cats_and_dogs.tar  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["# 현재 폴더\n","ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFyk5arjaRt_","executionInfo":{"status":"ok","timestamp":1670212395385,"user_tz":-540,"elapsed":238,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"c3d0a57b-f124-4c6a-9db7-79288f4fcf61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mcats_and_dogs\u001b[0m/  cats_and_dogs.tar  \u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalidation\u001b[0m/\n"]}]},{"cell_type":"code","source":["from google.colab import drive # 구글 드라이브에 연결 \n","drive.mount('/content/drive') # 내꺼 구글 드라이브에서 데이터를 가져옴 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-YLuwnwTS-4","executionInfo":{"status":"ok","timestamp":1670211890517,"user_tz":-540,"elapsed":2201,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"a8cafb89-87f9-4f9c-c926-cd6d58b6533a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IbfWN4F_Tt-K","executionInfo":{"status":"ok","timestamp":1670212033837,"user_tz":-540,"elapsed":264,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"bae58d8a-81a1-4396-ff1f-93dfedef3386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalidation\u001b[0m/\n"]}]},{"cell_type":"code","source":["train_dir = './cats_and_dogs/train'\n","validation_dir = './cats_and_dogs/validation'\n","test_dir = './cats_and_dogs/test' \n"],"metadata":{"id":"Ux6ZbAF1VA58"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# 훈련용 고양이 사진 디렉터리\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","\n","# 훈련용 강아지 사진 디렉터리\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","\n","# 검증용 고양이 사진 디렉터리\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","\n","# 검증용 강아지 사진 디렉터리\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n","\n","# 테스트용 고양이 사진 디렉터리\n","test_cats_dir = os.path.join(test_dir, 'cats')\n","\n","# 테스트용 강아지 사진 디렉터리\n","test_dogs_dir = os.path.join(test_dir, 'dogs') "],"metadata":{"id":"hrJeNMw0T1uL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","import scipy\n","\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","# 모든 이미지를 1/255 부동소수점으로 스케일을 조정하는 제너레이터 객체를 만들자.\n","train_datagen = ImageDataGenerator(rescale=1./255)  # 옛날 책 \n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(       \n","        train_dir,                # 타깃 디렉터리\n","        target_size=(150, 150),  # 모든 이미지를 150 × 150 크기로 바꿉니다\n","        batch_size=20,           #  20개씩 배치로 생산        \n","        class_mode='binary')     # 이진 레이블. 만약 다중클래스라면 'categorical'\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')\n","\n","test_generator = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')\n","# 아래에 tranin images가 2000개 임을 보아 두어라. \n","# 증식해도 2000개가 된다. 나중에 제너레이터 하는 순간에 변형하는 듯 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEzcJoxdUtWW","executionInfo":{"status":"ok","timestamp":1670212544731,"user_tz":-540,"elapsed":383,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"270eb7d0-7488-4085-9fb3-0137eaa04fe4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2000 images belonging to 2 classes.\n","Found 1000 images belonging to 2 classes.\n","Found 1000 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["from keras import layers\n","from keras import models\n","\n","\n","model = models.Sequential()\n","#layers.Conv2D\n","#layers.MaxPool2D\n","\n","model.add(layers.Conv2D(filters=32, kernel_size= (3,3), activation=\"relu\", input_shape=(150, 150, 3)))\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add(layers.Conv2D(filters=64, kernel_size= (3,3), activation=\"relu\"))\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add(layers.Conv2D(filters=128, kernel_size= (3,3), activation=\"relu\"))\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add(layers.Conv2D(filters=128, kernel_size= (3,3), activation=\"relu\"))\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","\n","\n","\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(units=512, activation= 'relu' ))\n","model.add(layers.Dense(units=1, activation= 'sigmoid')) "],"metadata":{"id":"djLuKvO7WYN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy',  # 이진이므로 loss는 binary_crossentropy\n","              optimizer='RMSprop',\n","              metrics=['accuracy'])\n","\n","model.fit(train_generator, \n","      steps_per_epoch=100, # train의 모든 이미지수는 2,000(고양이 1,000, 강아지 1,000)이고 배치가 20이므로 steps_per_epoch=100이어야 한다.\n","      epochs=5)\n","# https://tykimos.github.io/2017/03/08/CNN_Getting_Started/참고 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O98wIXg6Wq6D","executionInfo":{"status":"ok","timestamp":1670213180178,"user_tz":-540,"elapsed":628894,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"d6ab6977-b71b-4059-814e-2353e3e82e11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","100/100 [==============================] - 100s 981ms/step - loss: 0.8200 - accuracy: 0.5315\n","Epoch 2/5\n","100/100 [==============================] - 97s 968ms/step - loss: 0.7050 - accuracy: 0.5445\n","Epoch 3/5\n","100/100 [==============================] - 97s 972ms/step - loss: 0.6649 - accuracy: 0.6325\n","Epoch 4/5\n","100/100 [==============================] - 101s 1s/step - loss: 0.5988 - accuracy: 0.6820\n","Epoch 5/5\n","100/100 [==============================] - 103s 1s/step - loss: 0.5444 - accuracy: 0.7325\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7fe999c9a0>"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["model.evaluate(test_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zptzh4fCXGZJ","executionInfo":{"status":"ok","timestamp":1670215164908,"user_tz":-540,"elapsed":15499,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"c5b24b96-2af7-401a-8af7-242fa6855cf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["50/50 [==============================] - 15s 297ms/step - loss: 0.6631 - accuracy: 0.6520\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6631374955177307, 0.6520000100135803]"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvlGctwVX2jK","executionInfo":{"status":"ok","timestamp":1670216296636,"user_tz":-540,"elapsed":264,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"81f60803-dfbb-4f04-e159-adb703b5e898"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 15, 15, 128)       147584    \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 7, 7, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_1 (Flatten)         (None, 6272)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               3211776   \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 3,453,121\n","Trainable params: 3,453,121\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# 세가지 주 컴퓨터 비전 작업 "],"metadata":{"id":"LcdSSKz574A1"}},{"cell_type":"code","source":["# !  cmd 창으로 보냄 \n","!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n","!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n","!tar -xvf images.tar.gz\n","!tar -xvf annotations.tar.gz "],"metadata":{"id":"zt7X1OVHX5qy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","input_dir = \"images/\"\n","target_dir = \"annotations/trimaps/\"\n","\n","input_img_paths = sorted(\n","    [os.path.join(input_dir, fname)\n","     for fname in os.listdir(input_dir)\n","     if fname.endswith(\".jpg\")]) # jpg로 끝나는 것만 \n","target_paths = sorted(\n","    [os.path.join(target_dir, fname)\n","     for fname in os.listdir(target_dir)\n","     if fname.endswith(\".png\") and not fname.startswith(\".\")]) "],"metadata":{"id":"9lAQEu-N8GIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_img_paths"],"metadata":{"id":"fAzjsxSL9CWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from tensorflow.keras.utils import load_img, img_to_array\n","plt.axis(\"off\")\n","plt.imshow(load_img(input_img_paths[9]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"lT3dGIeT9eUQ","executionInfo":{"status":"error","timestamp":1670552732683,"user_tz":-540,"elapsed":1805,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"8503c673-d33d-4290-d7a7-e36f969fae31"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-be8990e4f46c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_wrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/api/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/api/keras/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreuters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/api/keras/datasets/imdb/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_word_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_wrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/datasets/imdb.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_remove_long_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \"\"\"\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndimage\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/linalg/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    193\u001b[0m \"\"\"  # noqa: E501\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdecomp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/linalg/misc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mblas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_blas_funcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlapack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/linalg/blas.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_fblas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_cblas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def display_target(target_array):\n","  normalized_array =(target_array -1)*127\n","  plt.axis(\"off\")\n","  plt.imshow(normalized_array[:, :, 0])\n","\n","img =img_to_array(load_img(target_paths[9], color_mode=\"grayscale\"))\n","display_target(img)"],"metadata":{"id":"jHf07d0N-EbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def display_target(target_array):\n","  normalized_array =(target_array.astype(\"uint8\") -1)*127# uint 데이터 크기 줄임 \n","  plt.axis(\"off\")\n","  plt.imshow(normalized_array[:, :, 0])\n","\n","img =img_to_array(load_img(target_paths[9], color_mode=\"grayscale\"))\n","display_target(img)"],"metadata":{"id":"vA_OxCSd-xdS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_to_array(load_img(target_paths[9], color_mode=\"grayscale\"))"],"metadata":{"id":"4YC8Ftfs_Zha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import random\n","\n","img_size = (200, 200)\n","num_imgs = len(input_img_paths)\n","\n","random.Random(1337).shuffle(input_img_paths)\n","random.Random(1337).shuffle(target_paths)\n","\n","def path_to_input_image(path):\n","    return img_to_array(load_img(path, target_size=img_size))\n","\n","def path_to_target(path):\n","    img = img_to_array(\n","        load_img(path, target_size=img_size, color_mode=\"grayscale\"))\n","    img = img.astype(\"uint8\") - 1\n","    return img\n","\n","input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n","targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n","for i in range(num_imgs):\n","    input_imgs[i] = path_to_input_image(input_img_paths[i])\n","    targets[i] = path_to_target(target_paths[i])\n","\n","num_val_samples = 1000\n","train_input_imgs = input_imgs[:-num_val_samples]\n","train_targets = targets[:-num_val_samples]\n","val_input_imgs = input_imgs[-num_val_samples:]\n","val_targets = targets[-num_val_samples:] "],"metadata":{"id":"kmNXeuGp_cE8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(200,200)+(3,)"],"metadata":{"id":"UWa0NXd2AQx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","def get_model(img_size, num_classes):\n","    inputs = keras.Input(shape=img_size + (3,))\n","    x = layers.Rescaling(1./255)(inputs)\n","\n","    x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x) # stride2에 의해 크기가 반으로 줄임 same있어도 반\n","    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x) # 필터는 64개\n","    x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x) # 필터 128개\n","    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n","    x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n","    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n","\n","    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)  # same 주변을 0으로 감싼다..\n","    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)# transpose 역방향으로감 \n","    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n","    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n","    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n","    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x) # 처음과 같음\n","\n","    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x) #3은  전경 배경 윤곽\n","\n","    model = keras.Model(inputs, outputs)\n","    return model\n","\n","model = get_model(img_size=img_size, num_classes=3)\n","model.summary() "],"metadata":{"id":"xPbInEmIBy4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"oxford_segmentation.keras\",\n","                                    save_best_only=True)\n","]\n","\n","history = model.fit(train_input_imgs, train_targets,\n","                    epochs=50,\n","                    callbacks=callbacks,\n","                    batch_size=64,\n","                    validation_data=(val_input_imgs, val_targets)) "],"metadata":{"id":"SBpNeVU5Cqa1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CelebA 데이터셋 준비하기"],"metadata":{"id":"-s3DzXp2Sgs4"}},{"cell_type":"code","source":["import gdown\n","url = \"https://drive.google.com/uc?id=1lY922EZj1o3-q9gpTeVXNis2SU2LdPX8\"\n","gdown.download(url, \"celeba_gan.tar\") "],"metadata":{"id":"R49X5MQgIJaK","colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"status":"ok","timestamp":1670479597228,"user_tz":-540,"elapsed":9921,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"f5228076-f7ac-4e95-a362-e77014ecccc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1lY922EZj1o3-q9gpTeVXNis2SU2LdPX8\n","To: /content/celeba_gan.tar\n","100%|██████████| 15.5M/15.5M [00:00<00:00, 180MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'celeba_gan.tar'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["!tar -xvf celeba_gan.tar"],"metadata":{"id":"VjzO5huCV8AI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dz7DVG-qWIQE","executionInfo":{"status":"ok","timestamp":1670479648355,"user_tz":-540,"elapsed":368,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"c8073493-9a3b-4376-d915-4ae0d8675a8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mceleba_gan\u001b[0m/  celeba_gan.tar  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["from tensorflow import keras\n","\n","dataset =keras.utils.image_dataset_from_directory(\n","    \"celeba_gan\",\n","     label_mode=None,\n","     image_size=(64,64),\n","    batch_size=32,\n","    smart_resize=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wx1F4xhaPhDO","executionInfo":{"status":"ok","timestamp":1670479667749,"user_tz":-540,"elapsed":3204,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"0649c45e-7d6d-41ee-a021-b4f6602edab1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2000 files belonging to 1 classes.\n"]}]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R52q5IANxraj","executionInfo":{"status":"ok","timestamp":1670486880106,"user_tz":-540,"elapsed":573,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"42ad7d28-6a36-4827-ddaa-84d1a847f535"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<MapDataset element_spec=TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None)>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["dataset =dataset.map(lambda x : x/255.)"],"metadata":{"id":"ANGQAIzrQmZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers\n"," # stride는 두칸띈다.\n","discriminator = keras.Sequential(\n","    [\n","        keras.Input(shape=(64, 64, 3)),\n","        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Flatten(),\n","        layers.Dropout(0.2),\n","        layers.Dense(1, activation=\"sigmoid\"),\n","    ],\n","    name=\"discriminator\",\n",") "],"metadata":{"id":"KjTP23V8N204"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["discriminator.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqwzD7BuXXGj","executionInfo":{"status":"ok","timestamp":1670479980023,"user_tz":-540,"elapsed":5,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"45365ebc-5303-4e7d-dd7e-a48403e5fce1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"discriminator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_3 (Conv2D)           (None, 32, 32, 64)        3136      \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 64)        0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 16, 16, 128)       131200    \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 8, 8, 128)         262272    \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 128)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 8193      \n","                                                                 \n","=================================================================\n","Total params: 404,801\n","Trainable params: 404,801\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["latent_dim =128\n","\n","generator = keras.Sequential(\n","    [\n","        keras.Input(shape=(latent_dim,)),\n","        layers.Dense(8*8*128),\n","        layers.Reshape((8,8,128)),\n","        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n","    ],\n","    name=\"generator\",\n",") "],"metadata":{"id":"Tpi12hdLN1Ks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator.summary() #파라미터가 10배 더 많음 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZFbtNbeCWjLb","executionInfo":{"status":"ok","timestamp":1670479957719,"user_tz":-540,"elapsed":350,"user":{"displayName":"정재훈","userId":"01263813800591133648"}},"outputId":"788fbe80-11f1-4398-e7c7-afdcad740a4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"generator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1 (Dense)             (None, 8192)              1056768   \n","                                                                 \n"," reshape (Reshape)           (None, 8, 8, 128)         0         \n","                                                                 \n"," conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n"," nspose)                                                         \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 128)       0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n"," ranspose)                                                       \n","                                                                 \n"," leaky_re_lu_6 (LeakyReLU)   (None, 32, 32, 256)       0         \n","                                                                 \n"," conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n"," ranspose)                                                       \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 64, 64, 512)       0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 64, 64, 3)         38403     \n","                                                                 \n","=================================================================\n","Total params: 3,979,651\n","Trainable params: 3,979,651\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","class GAN(keras.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super().__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n","        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n","\n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super(GAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","\n","    @property\n","    def metrics(self):\n","        return [self.d_loss_metric, self.g_loss_metric]\n","\n","    def train_step(self, real_images):\n","        batch_size = tf.shape(real_images)[0]\n","        random_latent_vectors = tf.random.normal(\n","            shape=(batch_size, self.latent_dim))\n","        generated_images = self.generator(random_latent_vectors)  \n","        combined_images = tf.concat([generated_images, real_images], axis=0)\n","        labels = tf.concat(\n","            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))],\n","            axis=0\n","        )\n","        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n","\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(combined_images)\n","            d_loss = self.loss_fn(labels, predictions)\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","        self.d_optimizer.apply_gradients(\n","            zip(grads, self.discriminator.trainable_weights)\n","        )\n","\n","        ################\n","\n","        random_latent_vectors = tf.random.normal(\n","            shape=(batch_size, self.latent_dim))\n","\n","        misleading_labels = tf.zeros((batch_size, 1))\n","\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(\n","                self.generator(random_latent_vectors))\n","            g_loss = self.loss_fn(misleading_labels, predictions)\n","        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(\n","            zip(grads, self.generator.trainable_weights))\n","\n","        self.d_loss_metric.update_state(d_loss)\n","        self.g_loss_metric.update_state(g_loss)\n","        return {\"d_loss\": self.d_loss_metric.result(),\n","                \"g_loss\": self.g_loss_metric.result()} "],"metadata":{"id":"h3id34yud0gi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GANMonitor(keras.callbacks.Callback):\n","    def __init__(self, num_img=3, latent_dim=128):\n","        self.num_img = num_img\n","        self.latent_dim = latent_dim\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n","        generated_images = self.model.generator(random_latent_vectors)\n","        generated_images *= 255\n","        generated_images.numpy()\n","        for i in range(self.num_img):\n","            img = keras.utils.array_to_img(generated_images[i])\n","            img.save(f\"generated_img_{epoch:03d}_{i}.png\") "],"metadata":{"id":"o_HHEt3iXUgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 100\n","gan =GAN(discriminator=discriminator, generator= generator, latent_dim=latent_dim)\n","gan.compile(\n","    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","    loss_fn =keras.losses.BinaryCrossentropy(),\n",")\n","\n","gan.fit(dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)])"],"metadata":{"id":"ZIATnM-BeHG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X14ZBvWCfaww"},"execution_count":null,"outputs":[]}]}